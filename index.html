<!DOCTYPE html>
<html lang="zh">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title> roc - roc的博客|Cloud Native|Kubernetes|Go|Golang|Service Mesh</title>
  <meta name="description" content="roc的博客|Cloud Native|Kubernetes|Go|Golang|Service Mesh" />
  <meta property="og:title" content="roc" />
  <meta name="twitter:title" content="roc" />
  <meta name="author" content="{Description { .Site.Author.name }}"/>
  <link href='https://imroc.io/favicon.png' rel='icon' type='image/x-icon'/>
  <meta property="og:image" content="https://res.cloudinary.com/imroc/image/upload/v1521031841/avatar.png" />
  <meta name="twitter:image" content="https://res.cloudinary.com/imroc/image/upload/v1521031841/avatar.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@imrocchan" />
  <meta name="twitter:creator" content="@imrocchan" />
  <meta property="og:url" content="https://imroc.io/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="roc" />

  <meta name="generator" content="Hugo 0.65.3" />
  <link rel="canonical" href="https://imroc.io/" />
  <link rel="alternate" href="https://imroc.io/index.xml" type="application/rss+xml" title="roc"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css"
    integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/5.5.0/css/fontawesome.min.css"
    integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.bootcss.com/twitter-bootstrap/3.3.7/css/bootstrap.min.css"
    integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">

  






<link rel="stylesheet" href='/css/bundle.min.8fad4c9e81931afed0cc9eee450df2ae0e60d1129a4cd7ee011629c97c6394e9.css' integrity='sha256-j61MnoGTGv7QzJ7uRQ3yrg5g0RKaTNfuARYpyXxjlOk='><script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?05e1e8b7484a08c51cd0953664168cd7";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


</head>

  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">切换导航</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://imroc.io/">roc</a>
    </div>
    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" href="javascript:void(0)">分类</a>
              <div class="navlinks-children">
                
                
                  <a href="https://imroc.io/categories/kubernetes">kubernetes</a>
                
                
                  <a href="https://imroc.io/categories/docker">docker</a>
                
                
                  <a href="https://imroc.io/categories/golang">golang</a>
                
                
                  <a href="https://imroc.io/categories/geek">geek</a>
                
                
                  <a href="https://imroc.io/categories/istio">istio</a>
                
              </div>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" href="javascript:void(0)">书籍</a>
              <div class="navlinks-children">
                
                
                  <a href="https://k8s.imroc.io">Kubernetes 实践指南</a>
                
                
                  <a href="https://istio.imroc.io">Istio 实践指南</a>
                
                
                  <a href="https://book.kubetencent.io">腾讯云容器服务指南</a>
                
              </div>
            </li>
          
        

        
          
            <li>
              
                
              
                
                  <a href="/en" lang="en">English</a>
                
              
            </li>
          
        

        
        <li>
          <a href="#modalSearch" data-toggle="modal" data-target="#modalSearch" style="outline: none;">
            <span id="searchGlyph" class="glyphicon glyphicon-search"></span>
          </a>
        </li>
        
      </ul>
    </div>
    <div class="avatar-container">
      <div class="avatar-img-border">
        
          <a title="roc" href="https://imroc.io/">
            <img class="avatar-img" src="https://res.cloudinary.com/imroc/image/upload/v1521031841/avatar.png" alt="roc" />
          </a>
        
      </div>
    </div>
  </div>
</nav>


  <div id="modalSearch" class="modal fade" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal">&times;</button>
          <h4 class="modal-title">搜索</h4>
        </div>
        <div class="modal-body">
            
<div class="aa-input-container" id="aa-input-container">
    <input type="search" id="aa-search-input" class="aa-input-search" placeholder="Search for titles or URIs..."
        name="search" autocomplete="off" />
    <svg class="aa-input-icon" viewBox="654 -372 1664 1664">
        <path
            d="M1806,332c0-123.3-43.8-228.8-131.5-316.5C1586.8-72.2,1481.3-116,1358-116s-228.8,43.8-316.5,131.5  C953.8,103.2,910,208.7,910,332s43.8,228.8,131.5,316.5C1129.2,736.2,1234.7,780,1358,780s228.8-43.8,316.5-131.5  C1762.2,560.8,1806,455.3,1806,332z M2318,1164c0,34.7-12.7,64.7-38,90s-55.3,38-90,38c-36,0-66-12.7-90-38l-343-342  c-119.3,82.7-252.3,124-399,124c-95.3,0-186.5-18.5-273.5-55.5s-162-87-225-150s-113-138-150-225S654,427.3,654,332  s18.5-186.5,55.5-273.5s87-162,150-225s138-113,225-150S1262.7-372,1358-372s186.5,18.5,273.5,55.5s162,87,225,150s113,138,150,225  S2062,236.7,2062,332c0,146.7-41.3,279.7-124,399l343,343C2305.7,1098.7,2318,1128.7,2318,1164z" />
    </svg>
</div>

<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/algoliasearch.min.js"></script>
<script src="https://res.cloudinary.com/jimmysong/raw/upload/rootsongjc-hugo/autocomplete.min.js"></script>
<script>
    var client = algoliasearch("B6Q6PSGUV5", "5b4678e9995fe4211c4fa43ad2ffdab5");
    var index = client.initIndex("imroc-blog");
    
    autocomplete('#aa-search-input', {
        hint: false
    }, {
        source: autocomplete.sources.hits(index, {
            hitsPerPage: 5
        }),
        
        displayKey: 'name',
        
        templates: {
            
            suggestion: function (suggestion) {
                return '<span>' + '<a href="/' + suggestion.uri + '">' + suggestion._highlightResult.title.value +
                        '</a></span>';
            }
        }
    });
</script>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">close</button>
        </div>
      </div>
    </div>
  </div>

    
  
  
  
  




  
    <div id="header-big-imgs" data-num-img=1 data-img-src-1="https://res.cloudinary.com/imroc/image/upload/v1515849754/blog/banner/hacker.jpg" data-img-desc-1="Hacker"></div>
  

  <header class="header-section has-img">
    
      <div class="intro-header big-img">
        
        
        <div class="container">
          <div class="row">
              <div class="col-lg-12 col-md-12 col-md-offset-0">
                
                <div class="page-heading">
                
                  
                     <h1 align="center">Hi,I&#39;m Roc</h1>
                  
                  
              </div>
            </div>
          </div>
        </div>
        <span class="img-desc" style="display: inline;"></span>
      </div>
    
    <div class="intro-header no-img">
      
      <div class="container">
        <div class="row">
          <div class="col-lg-12 col-md-12 col-md-offset-0">
            <div class="page-heading">
                <h1 align="center">roc</h1>
                
                
                  <span class="post-meta">
  
  &nbsp;&bull;&nbsp; 其它语言: <a href="https://imroc.io/en/" lang="en">English</a>
</span>


                
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    <div role="main" class="container">
    <div class="row">
      <div class="col-lg-8 col-md-10">
        

        <div class="posts-list">
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/build-cloud-native-large-scale-distributed-monitoring-system-3/">
                <h2 class="post-title">打造云原生大型分布式监控系统(三): Thanos 部署与实践</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2020-04-19
  
  
</span>


              <div class="post-entry">
                
                  概述 上一篇 Thanos 架构详解 我们深入理解了 thanos 的架构设计与实现原理，现在我们来聊聊实战，分享一下如何部署和使用 Thanos。 部署方式 本文聚焦 Thanos 的云原生
                  <a href="https://imroc.io/posts/build-cloud-native-large-scale-distributed-monitoring-system-3/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/build-cloud-native-large-scale-distributed-monitoring-system-2/">
                <h2 class="post-title">打造云原生大型分布式监控系统(二): Thanos 架构详解</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2020-04-06
  
  
</span>


              <div class="post-entry">
                
                  <h2 id="概述">概述</h2>
<p>之前在 <a href="../build-cloud-native-large-scale-distributed-monitoring-system-1">大规模场景下 Prometheus 的优化手段</a> 中，我们想尽 &ldquo;千方百计&rdquo; 才好不容易把 Prometheus 优化到适配大规模场景，部署和后期维护麻烦且复杂不说，还有很多不完美的地方，并且还无法满足一些更高级的诉求，比如查看时间久远的监控数据，对于一些时间久远不常用的 &ldquo;冷数据&rdquo;，最理想的方式就是存到廉价的对象存储中，等需要查询的时候能够自动加载出来。</p>
<p>Thanos (没错，就是灭霸) 可以帮我们简化分布式 Prometheus 的部署与管理，并提供了一些的高级特性：<strong>全局视图</strong>，<strong>长期存储</strong>，<strong>高可用</strong>。下面我们来详细讲解一下。</p>
                  <a href="https://imroc.io/posts/build-cloud-native-large-scale-distributed-monitoring-system-2/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/build-cloud-native-large-scale-distributed-monitoring-system-1/">
                <h2 class="post-title">打造云原生大型分布式监控系统(一): 大规模场景下 Prometheus 的优化手段</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2020-03-26
  
  
</span>


              <div class="post-entry">
                
                  <h2 id="概述">概述</h2>
<p>Prometheus 几乎已成为监控领域的事实标准，它自带高效的时序数据库存储，可以让单台 Prometheus 能够高效的处理大量的数据，还有友好并且强大的 PromQL 语法，可以用来灵活的查询各种监控数据以及配置告警规则，同时它的 pull 模型指标采集方式被广泛采纳，非常多的应用都实现了 Prometheus 的 metrics 接口以暴露自身各项数据指标让 Prometheus 去采集，很多没有适配的应用也会有第三方 exporter 帮它去适配 Prometheus，所以监控系统我们通常首选用 Prometheus，本系列文章也将基于 Prometheus 来打造云原生环境下的大型分布式监控系统。</p>
<h2 id="大规模场景下-prometheus-的痛点">大规模场景下 Prometheus 的痛点</h2>
<p>Prometheus 本身只支持单机部署，没有自带支持集群部署，也就不支持高可用以及水平扩容，在大规模场景下，最让人关心的问题是它的存储空间也受限于单机磁盘容量，磁盘容量决定了单个 Prometheus 所能存储的数据量，数据量大小又取决于被采集服务的指标数量、服务数量、采集速率以及数据过期时间。在数据量大的情况下，我们可能就需要做很多取舍，比如丢弃不重要的指标、降低采集速率、设置较短的数据过期时间(默认只保留15天的数据，看不到比较久远的监控数据)。</p>
<p>这些痛点实际也是可以通过一些优化手段来改善的，下面我们来细讲一下。</p>
                  <a href="https://imroc.io/posts/build-cloud-native-large-scale-distributed-monitoring-system-1/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/kubernetes-overflow-and-drop/">
                <h2 class="post-title">Kubernetes 疑难杂症排查分享：神秘的溢出与丢包</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2020-01-12
  
  
</span>


              <div class="post-entry">
                
                  <blockquote>
<p>上一篇 <a href="https://imroc.io/posts/kubernetes/kubernetes-no-route-to-host/">Kubernetes 疑难杂症排查分享: 诡异的 No route to host</a> 不小心又爆火，这次继续带来干货，看之前请提前泡好茶，避免口干。</p>
</blockquote>
<h2 id="问题描述">问题描述</h2>
<p>有用户反馈大量图片加载不出来。</p>
<p>图片下载走的 k8s ingress，这个 ingress 路径对应后端 service 是一个代理静态图片文件的 nginx deployment，这个 deployment 只有一个副本，静态文件存储在 nfs 上，nginx 通过挂载 nfs 来读取静态文件来提供图片下载服务，所以调用链是：client &ndash;&gt; k8s ingress &ndash;&gt; nginx &ndash;&gt; nfs。</p>
<h2 id="猜测">猜测</h2>
<p>猜测: ingress 图片下载路径对应的后端服务出问题了。</p>
<p>验证：在 k8s 集群直接 curl nginx 的 pod ip，发现不通，果然是后端服务的问题！</p>
<h2 id="抓包">抓包</h2>
<p>继续抓包测试观察，登上 nginx pod 所在节点，进入容器的 netns 中：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#75715e"># 拿到 pod 中 nginx 的容器 id</span>
$ kubectl describe pod tcpbench-6484d4b457-847gl | grep -A10 <span style="color:#e6db74">&#34;^Containers:&#34;</span> | grep -Eo <span style="color:#e6db74">&#39;docker://.*$&#39;</span> | head -n <span style="color:#ae81ff">1</span> | sed <span style="color:#e6db74">&#39;s/docker:\/\/\(.*\)$/\1/&#39;</span>
49b4135534dae77ce5151c6c7db4d528f05b69b0c6f8b9dd037ec4e7043c113e

<span style="color:#75715e"># 通过容器 id 拿到 nginx 进程 pid</span>
$ docker inspect -f <span style="color:#f92672">{{</span>.State.Pid<span style="color:#f92672">}}</span> 49b4135534dae77ce5151c6c7db4d528f05b69b0c6f8b9dd037ec4e7043c113e
<span style="color:#ae81ff">3985</span>

<span style="color:#75715e"># 进入 nginx 进程所在的 netns</span>
$ nsenter -n -t <span style="color:#ae81ff">3985</span>

<span style="color:#75715e"># 查看容器 netns 中的网卡信息，确认下</span>
$ ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
3: eth0@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc noqueue state UP group default
    link/ether 56:04:c7:28:b0:3c brd ff:ff:ff:ff:ff:ff link-netnsid <span style="color:#ae81ff">0</span>
    inet 172.26.0.8/26 scope global eth0
       valid_lft forever preferred_lft forever
</code></pre></div><p>使用 tcpdump 指定端口 24568 抓容器 netns 中 eth0 网卡的包:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">tcpdump -i eth0 -nnnn -ttt port <span style="color:#ae81ff">24568</span>
</code></pre></div><p>在其它节点准备使用 nc 指定源端口为 24568 向容器发包：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">nc -u <span style="color:#ae81ff">24568</span> 172.16.1.21 <span style="color:#ae81ff">80</span>
</code></pre></div><p>观察抓包结果：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">00:00:00.000000 IP 10.0.0.3.24568 &gt; 172.16.1.21.80: Flags <span style="color:#f92672">[</span>S<span style="color:#f92672">]</span>, seq 416500297, win 29200, options <span style="color:#f92672">[</span>mss 1424,sackOK,TS val <span style="color:#ae81ff">3000206334</span> ecr 0,nop,wscale 9<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
00:00:01.032218 IP 10.0.0.3.24568 &gt; 172.16.1.21.80: Flags <span style="color:#f92672">[</span>S<span style="color:#f92672">]</span>, seq 416500297, win 29200, options <span style="color:#f92672">[</span>mss 1424,sackOK,TS val <span style="color:#ae81ff">3000207366</span> ecr 0,nop,wscale 9<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
00:00:02.011962 IP 10.0.0.3.24568 &gt; 172.16.1.21.80: Flags <span style="color:#f92672">[</span>S<span style="color:#f92672">]</span>, seq 416500297, win 29200, options <span style="color:#f92672">[</span>mss 1424,sackOK,TS val <span style="color:#ae81ff">3000209378</span> ecr 0,nop,wscale 9<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
00:00:04.127943 IP 10.0.0.3.24568 &gt; 172.16.1.21.80: Flags <span style="color:#f92672">[</span>S<span style="color:#f92672">]</span>, seq 416500297, win 29200, options <span style="color:#f92672">[</span>mss 1424,sackOK,TS val <span style="color:#ae81ff">3000213506</span> ecr 0,nop,wscale 9<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
00:00:08.192056 IP 10.0.0.3.24568 &gt; 172.16.1.21.80: Flags <span style="color:#f92672">[</span>S<span style="color:#f92672">]</span>, seq 416500297, win 29200, options <span style="color:#f92672">[</span>mss 1424,sackOK,TS val <span style="color:#ae81ff">3000221698</span> ecr 0,nop,wscale 9<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
00:00:16.127983 IP 10.0.0.3.24568 &gt; 172.16.1.21.80: Flags <span style="color:#f92672">[</span>S<span style="color:#f92672">]</span>, seq 416500297, win 29200, options <span style="color:#f92672">[</span>mss 1424,sackOK,TS val <span style="color:#ae81ff">3000237826</span> ecr 0,nop,wscale 9<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
00:00:33.791988 IP 10.0.0.3.24568 &gt; 172.16.1.21.80: Flags <span style="color:#f92672">[</span>S<span style="color:#f92672">]</span>, seq 416500297, win 29200, options <span style="color:#f92672">[</span>mss 1424,sackOK,TS val <span style="color:#ae81ff">3000271618</span> ecr 0,nop,wscale 9<span style="color:#f92672">]</span>, length <span style="color:#ae81ff">0</span>
</code></pre></div><p>SYN 包到容器内网卡了，但容器没回 ACK，像是报文到达容器内的网卡后就被丢了。看样子跟防火墙应该也没什么关系，也检查了容器 netns 内的 iptables 规则，是空的，没问题。</p>
<p>排除是 iptables 规则问题，在容器 netns 中使用 <code>netstat -s</code> 检查下是否有丢包统计:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ netstat -s | grep -E <span style="color:#e6db74">&#39;overflow|drop&#39;</span>
    <span style="color:#ae81ff">12178939</span> times the listen queue of a socket overflowed
    <span style="color:#ae81ff">12247395</span> SYNs to LISTEN sockets dropped
</code></pre></div><p>果然有丢包，为了理解这里的丢包统计，我深入研究了一下，下面插播一些相关知识。</p>
                  <a href="https://imroc.io/posts/kubernetes-overflow-and-drop/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/kubernetes-no-route-to-host/">
                <h2 class="post-title">Kubernetes 疑难杂症排查分享: 诡异的 No route to host</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2019-12-15
  
  
</span>


              <div class="post-entry">
                
                  <p>之前发过一篇干货满满的爆火文章 <a href="https://imroc.io/posts/kubernetes/troubleshooting-with-kubernetes-network/">Kubernetes 网络疑难杂症排查分享</a>，包含多个疑难杂症的排查案例分享，信息量巨大。这次我又带来了续集，只讲一个案例，但信息量也不小，Are you ready ?</p>
<h2 id="问题反馈">问题反馈</h2>
<p>有用户反馈 Deployment 滚动更新的时候，业务日志偶尔会报 &ldquo;No route to host&rdquo; 的错误。</p>
<h2 id="分析">分析</h2>
<p>之前没遇到滚动更新会报 &ldquo;No route to host&rdquo; 的问题，我们先看下滚动更新导致连接异常有哪些常见的报错:</p>
<ul>
<li>
<p><code>Connection reset by peer</code>: 连接被重置。通常是连接建立过，但 server 端发现 client 发的包不对劲就返回 RST，应用层就报错连接被重置。比如在 server 滚动更新过程中，client 给 server 发的请求还没完全结束，或者本身是一个类似 grpc 的多路复用长连接，当 server 对应的旧 Pod 删除(没有做优雅结束，停止时没有关闭连接)，新 Pod 很快创建启动并且刚好有跟之前旧 Pod 一样的 IP，这时 kube-proxy 也没感知到这个 IP 其实已经被删除然后又被重建了，针对这个 IP 的规则就不会更新，旧的连接依然发往这个 IP，但旧 Pod 已经不在了，后面继续发包时依然转发给这个 Pod IP，最终会被转发到这个有相同 IP 的新 Pod 上，而新 Pod 收到此包时检查报文发现不对劲，就返回 RST 给 client 告知将连接重置。针对这种情况，建议应用自身处理好优雅结束：Pod 进入 Terminating 状态后会发送 <code>SIGTERM</code> 信号给业务进程，业务进程的代码需处理这个信号，在进程退出前关闭所有连接。</p>
</li>
<li>
<p><code>Connection refused</code>: 连接被拒绝。通常是连接还没建立，client 正在发 SYN 包请求建立连接，但到了 server 之后发现端口没监听，内核就返回 RST 包，然后应用层就报错连接被拒绝。比如在 server 滚动更新过程中，旧的 Pod 中的进程很快就停止了(网卡还未完全销毁)，但 client 所在节点的 iptables/ipvs 规则还没更新，包就可能会被转发到了这个停止的 Pod (由于 k8s 的 controller 模式，从 Pod 删除到 service 的 endpoint 更新，再到 kube-proxy watch 到更新并更新 节点上的 iptables/ipvs 规则，这个过程是异步的，中间存在一点时间差，所以有可能存在 Pod 中的进程已经没有监听，但 iptables/ipvs 规则还没更新的情况)。针对这种情况，建议给容器加一个 preStop，在真正销毁 Pod 之前等待一段时间，留时间给 kube-proxy 更新转发规则，更新完之后就不会再有新连接往这个旧 Pod 转发了，preStop 示例:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#66d9ef">lifecycle</span>:
  <span style="color:#66d9ef">preStop</span>:
    <span style="color:#66d9ef">exec</span>:
      <span style="color:#66d9ef">command</span>:
      - /bin/bash
      - -c
      - sleep <span style="color:#ae81ff">30</span>
</code></pre></div><p>另外，还可能是新的 Pod 启动比较慢，虽然状态已经 Ready，但实际上可能端口还没监听，新的请求被转发到这个还没完全启动的 Pod 就会报错连接被拒绝。针对这种情况，建议给容器加就绪检查 (readinessProbe)，让容器真正启动完之后才将其状态置为 Ready，然后 kube-proxy 才会更新转发规则，这样就能保证新的请求只被转发到完全启动的 Pod，readinessProbe 示例:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#66d9ef">readinessProbe</span>:
  <span style="color:#66d9ef">httpGet</span>:
    <span style="color:#66d9ef">path</span>: /healthz
    <span style="color:#66d9ef">port</span>: <span style="color:#ae81ff">80</span>
    <span style="color:#66d9ef">httpHeaders</span>:
    - <span style="color:#66d9ef">name</span>: X-Custom-Header
      <span style="color:#66d9ef">value</span>: Awesome
  <span style="color:#66d9ef">initialDelaySeconds</span>: <span style="color:#ae81ff">15</span>
  <span style="color:#66d9ef">timeoutSeconds</span>: <span style="color:#ae81ff">1</span>
</code></pre></div></li>
<li>
<p><code>Connection timed out</code>: 连接超时。通常是连接还没建立，client 发 SYN 请求建立连接一直等到超时时间都没有收到 ACK，然后就报错连接超时。这个可能场景跟前面 <code>Connection refused</code> 可能的场景类似，不同点在于端口有监听，但进程无法正常响应了: 转发规则还没更新，旧 Pod 的进程正在停止过程中，虽然端口有监听，但已经不响应了；或者转发规则更新了，新 Pod 端口也监听了，但还没有真正就绪，还没有能力处理新请求。针对这些情况的建议跟前面一样：加 preStop 和 readinessProbe。</p>
</li>
</ul>
<p>下面我们来继续分析下滚动更新时发生 <code>No route to host</code> 的可能情况。</p>
<p>这个报错很明显，IP 无法路由，通常是将报文发到了一个已经彻底销毁的 Pod (网卡已经不在)。不可能发到一个网卡还没创建好的 Pod，因为即便不加存活检查，也是要等到 Pod 网络初始化完后才可能 Ready，然后 kube-proxy 才会更新转发规则。</p>
<p>什么情况下会转发到一个已经彻底销毁的 Pod？ 借鉴前面几种滚动更新的报错分析，我们推测应该是 Pod 很快销毁了但转发规则还没更新，从而新的请求被转发了这个已经销毁的 Pod，最终报文到达这个 Pod 所在 PodCIDR 的 Node 上时，Node 发现本机已经没有这个 IP 的容器，然后 Node 就返回 ICMP 包告知 client 这个 IP 不可达，client 收到 ICMP 后，应用层就会报错 &ldquo;No route to host&rdquo;。</p>
<p>所以根据我们的分析，关键点在于 Pod 销毁太快，转发规则还没来得及更新，导致后来的请求被转发到已销毁的 Pod。针对这种情况，我们可以给容器加一个 preStop，留时间给 kube-proxy 更新转发规则来解决，参考 《Kubernetes实践指南》中的部分章节: <a href="https://k8s.imroc.io/best-practice/high-availability-deployment-of-applications#smooth-update-using-prestophook-and-readinessprobe">https://k8s.imroc.io/best-practice/high-availability-deployment-of-applications#smooth-update-using-prestophook-and-readinessprobe</a></p>
                  <a href="https://imroc.io/posts/kubernetes-no-route-to-host/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/kubernetes-service-topology/">
                <h2 class="post-title">k8s v1.17 新特性预告: 拓扑感知服务路由</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2019-11-26
  
  &nbsp;&bull;&nbsp; 其它语言: <a href="https://imroc.io/en/posts/kubernetes-service-topology/" lang="en">English</a>
</span>


              <div class="post-entry">
                
                  <p>今天给大家介绍下我参与开发的一个 k8s v1.17 新特性: 拓扑感知服务路由。</p>
<h2 id="名词解释">名词解释</h2>
<ul>
<li>拓扑域: 表示在集群中的某一类 &ldquo;地方&rdquo;，比如某节点、某机架、某可用区或某地域等，这些都可以作为某种拓扑域。</li>
<li>endpoint: k8s 某个服务的某个 ip+port，通常是 pod 的 ip+port。</li>
<li>service: k8s 的 service 资源(服务)，关联一组 endpoint ，访问 service 会被转发到关联的某个 endpoint 上。</li>
</ul>
<h2 id="背景">背景</h2>
<p>拓扑感知服务路由，此特性最初由杜军大佬提出并设计。为什么要设计此特性呢？想象一下，k8s 集群节点分布在不同的地方，service 对应的 endpoints 分布在不同节点，传统转发策略会对所有 endpoint 做负载均衡，通常会等概率转发，当访问 service 时，流量就可能被分散打到这些不同的地方。虽然 service 转发做了负载均衡，但如果 endpoint 距离比较远，流量转发过去网络时延就相对比较高，会影响网络性能，在某些情况下甚至还可能会付出额外的流量费用。要是如能实现 service 就近转发 endpoint，是不是就可以实现降低网络时延，提升网络性能了呢？是的！这也正是该特性所提出的目的和意义。</p>
<h2 id="k8s-亲和性">k8s 亲和性</h2>
<p>service 的就近转发实际就是一种网络的亲和性，倾向于转发到离自己比较近的 endpoint。在此特性之前，已经在调度和存储方面有一些亲和性的设计与实现:</p>
<ul>
<li>节点亲和性 (Node Affinity): 让 Pod 被调度到符合一些期望条件的 Node 上，比如限制调度到某一可用区，或者要求节点支持 GPU，这算是调度亲和，调度结果取决于节点属性。</li>
<li>Pod 亲和性与反亲和性 (Pod Affinity/AntiAffinity): 让一组 Pod 调度到同一拓扑域的节点上，或者打散到不同拓扑域的节点， 这也算是调度亲和，调度结果取决于其它 Pod。</li>
<li>数据卷拓扑感知调度 (Volume Topology-aware Scheduling): 让 Pod 只被调度到符合其绑定的存储所在拓扑域的节点上，这算是调度与存储的亲和，调度结果取决于存储的拓扑域。</li>
<li>本地数据卷 (Local Persistent Volume): 让 Pod 使用本地数据卷，比如高性能 SSD，在某些需要高 IOPS 低时延的场景很有用，它还会保证 Pod 始终被调度到同一节点，数据就不会不丢失，这也算是调度与存储的亲和，调度结果取决于存储所在节点。</li>
<li>数据卷拓扑感知动态创建 (Topology-Aware Volume Dynamic Provisioning): 先调度 Pod，再根据 Pod 所在节点的拓扑域来创建存储，这算是存储与调度的亲和，存储的创建取决于调度的结果。</li>
</ul>
<p>而 k8s 目前在网络方面还没有亲和性能力，拓扑感知服务路由这个新特性恰好可以补齐这个的空缺，此特性使得 service 可以实现就近转发而不是所有 endpoint 等概率转发。</p>
                  <a href="https://imroc.io/posts/kubernetes-service-topology/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/troubleshooting-with-kubernetes-network/">
                <h2 class="post-title">Kubernetes 网络疑难杂症排查分享</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2019-08-12
  
  &nbsp;&bull;&nbsp; 其它语言: <a href="https://imroc.io/en/posts/troubleshooting-with-kubernetes-network/" lang="en">English</a>
</span>


              <div class="post-entry">
                
                  <p>大家好，我是 roc，来自腾讯云容器服务(TKE)团队，经常帮助用户解决各种 K8S 的疑难杂症，积累了比较丰富的经验，本文分享几个比较复杂的网络方面的问题排查和解决思路，深入分析并展开相关知识，信息量巨大，相关经验不足的同学可能需要细细品味才能消化，我建议收藏本文反复研读，当完全看懂后我相信你的功底会更加扎实，解决问题的能力会大大提升。</p>
<blockquote>
<p>本文发现的问题是在使用 TKE 时遇到的，不同厂商的网络环境可能不一样，文中会对不同的问题的网络环境进行说明</p>
</blockquote>
                  <a href="https://imroc.io/posts/troubleshooting-with-kubernetes-network/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/lost-packets-once-enable-tcp-tw-recycle/">
                <h2 class="post-title">Kubernetes 踩坑分享：开启tcp_tw_recycle内核参数在NAT环境会丢包</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2019-06-09
  
  
</span>


              <div class="post-entry">
                
                  原因 tcp_tw_recycle参数。它用来快速回收TIME_WAIT连接，不过如果在NAT环境下会引发问题。 RFC1323中有如下一段描述
                  <a href="https://imroc.io/posts/lost-packets-once-enable-tcp-tw-recycle/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/handle-memory-fragmentation/">
                <h2 class="post-title">Kubernetes 最佳实践：处理内存碎片化</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2019-06-08
  
  
</span>


              <div class="post-entry">
                
                  内存碎片化造成的危害 节点的内存碎片化严重，导致docker运行容器时，无法分到大的内存块，导致start docker失败。最终导致服务更新时
                  <a href="https://imroc.io/posts/handle-memory-fragmentation/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
            <article class="post-preview">
              <a href="https://imroc.io/posts/kubernetes-scale-keepalive-service/">
                <h2 class="post-title">Kubernetes 最佳实践：解决长连接服务扩容失效</h2>
                
              </a>

              <span class="post-meta">
  
  发表于 2019-06-06
  
  
</span>


              <div class="post-entry">
                
                  在现网运营中，有很多场景为了提高效率，一般都采用建立长连接的方式来请求。我们发现在客户端以长连接请求服务端的场景下，K8S的自动扩容会失效。
                  <a href="https://imroc.io/posts/kubernetes-scale-keepalive-service/" class="post-read-more">[阅读全文]</a>
                
              </div>

              
                <span class="post-meta">
                
                  #<a
                    href='https://imroc.io/tags/kubernetes/'>kubernetes</a>&nbsp;
                
                </span>
              
            </article>
          
        </div>

        
          <ul class="pager main-pager">
            
            
              <li class="next">
                <a href="/page/2">下一页 &rarr;</a>
              </li>
            
          </ul>
        
        <div align="center" class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
          

<ul class="pagination">
    
    <li class="page-item">
        <a href="/" class="page-link" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li class="page-item disabled">
    <a  class="page-link" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
    
        
        
    
    
    <li class="page-item active"><a class="page-link" href="/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/2/">2</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/3/">3</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/4/">4</a></li>
    
    
    <li class="page-item">
    <a href="/page/2/" class="page-link" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li class="page-item">
        <a href="/page/4/" class="page-link" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>


          
          
          
          
          
          
          
          
          
          
          
        </div>
      </div>
      <div class="col-lg-4 col-md-2">
        <div class="sidebar-wrap sidebar-about">
          <div class="about-img">
            <img src="/img/avatar.jpg" alt="roc" class="rounded-circle">
          </div>
          <p class="about-text">
            大家好，我是 roc，专注云原生技术领域，不定期分享容器、Kubernetes、Service Mesh 等相关干货。
          </p>
          
          <img src="https://res.cloudinary.com/imroc/image/upload/v1578973640/geek_daily_qrcode.jpg" alt="云原生知识宇宙">
          <p class="about-text">
            扫码关注 "云原生知识宇宙" 公众号可接收文章推送。
          </p>
          
        </div>
        
        <div class="sidebar-block">
          <h4 class="sidebar-title">标签</h4>
          <div class="list-unstyled tags-cloud">
            
            
            <a href="/tags/ci"><i class="fa fa-tags"></i> ci(1)</a>
            
            
            
            <a href="/tags/docker"><i class="fa fa-tags"></i> docker(1)</a>
            
            
            
            <a href="/tags/geek"><i class="fa fa-tags"></i> geek(4)</a>
            
            
            
            <a href="/tags/git"><i class="fa fa-tags"></i> git(1)</a>
            
            
            
            <a href="/tags/golang"><i class="fa fa-tags"></i> golang(4)</a>
            
            
            
            <a href="/tags/hugo"><i class="fa fa-tags"></i> hugo(1)</a>
            
            
            
            <a href="/tags/istio"><i class="fa fa-tags"></i> istio(1)</a>
            
            
            
            <a href="/tags/kubernetes"><i class="fa fa-tags"></i> kubernetes(21)</a>
            
            
          </div>
        </div>
      </div>
    </div>
  </div>

    <footer>
  <div id="copyright">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
          <ul class="list-inline text-center footer-links">
            
                <li>
                  <a href="mailto:roc@imroc.io" title="Email me">
                    <span class="fa-stack fa-lg">
                      <i class="fas fa-circle fa-stack-2x"></i>
                      <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>
                <li>
                  <a href="https://github.com/imroc" title="GitHub">
                    <span class="fa-stack fa-lg">
                      <i class="fas fa-circle fa-stack-2x"></i>
                      <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>
                <li>
                  <a href="https://twitter.com/imrocchan" title="Twitter">
                    <span class="fa-stack fa-lg">
                      <i class="fas fa-circle fa-stack-2x"></i>
                      <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                    </span>
                  </a>
                </li>
            
            <li>
              <a href="https://imroc.io/index.xml" title="RSS">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            
          </ul>
          <p class="credits copyright text-muted">
          &copy;2017-2020
            
              
                <a href="/about">roc</a>
              
            
            &nbsp;&bull;&nbsp;
            2020-04-19
            更新
          </p>
          <p class="credits theme-by text-muted">
            由 <a href="http://gohugo.io">Hugo v0.65.3</a> 强力驱动 &nbsp;&bull;&nbsp; 主题 <a href="https://github.com/imroc/xhugo">xhugo</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
  window.copyText='复制'==''?"Copy":'复制'
  window.copiedText='已复制!'==''?"Copied":'已复制!'
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js"
  integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js"
  integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script src="https://cdn.bootcss.com/jquery/1.12.4/jquery.min.js"
  integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://cdn.bootcss.com/twitter-bootstrap/3.3.7/js/bootstrap.min.js"
  integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>





<script src='/js/bundle.min.3e2cb25916e0577d6eaf45f0f6125a6156723011439209b222abd8207bb6057f.js' integrity='sha256-PiyyWRbgV31ur0Xw9hJaYVZyMBFDkgmyIqvYIHu2BX8='></script>






  </body>
</html>

